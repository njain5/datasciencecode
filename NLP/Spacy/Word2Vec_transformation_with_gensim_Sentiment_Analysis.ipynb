{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec transformation with gensim Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTH658A7OZdI",
        "colab_type": "text"
      },
      "source": [
        "# The data\n",
        "\n",
        "   ##  About the data\n",
        "The analysis seeks to establish transformation of word into vectors on any text. We are not concerned about whether the text data has label or not. The data set supplied consists of  **50000 IMDB reviews**  with review ID on a certain movie  with no labels.We'll use this unlabelled data to train a model. which can be applied on test data.\n",
        "\n",
        "Please visit the site to download the data\n",
        "https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UugZlvfilpe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8At5BFAOjSr",
        "colab_type": "text"
      },
      "source": [
        "## Import the data\n",
        "\n",
        "The data was imported from local repository using the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeRMt2_1OgGO",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d6cb734d-b149-4188-9f6e-7ce96d1a8d7b"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c020c300-6c17-4028-81a3-51f30278e29b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c020c300-6c17-4028-81a3-51f30278e29b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving unlabeledTrainData_lyst8653.tsv to unlabeledTrainData_lyst8653.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGcugk4kOn17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"unlabeledTrainData_lyst8653.tsv\",delimiter=\"\\t\",quoting=3,header=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ6SvF6MUugd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "416d7e8b-a5ed-4f19-88d3-551e9b75bd73"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I32TQb8VCQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re,string"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeX4JK1OVI2E",
        "colab_type": "text"
      },
      "source": [
        "##  Data Cleaning\n",
        "We've gone through the reviews & detected punctuations in many reviews.The punctuations don't contribute anything to our analysis & moreover they are considered as unique word & distort the meaning of other words.This is why the data needs to be cleaned before we jump into core analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jXnLERIVFZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n",
        "  try:\n",
        "    string=re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n",
        "    string=re.sub(r\"[^A-Za-z]\",\" \",string)\n",
        "    words=string.strip().lower().split()\n",
        "    return \" \".join(words)\n",
        "  except:\n",
        "    return \" \""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzOTuS18VTxq",
        "colab_type": "text"
      },
      "source": [
        "Above we defined a function called **clean_string** & this function we have applied on the raw review column and created a new column(**clean_review**) to save the cleaned reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkq4eHPGVQPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['clean_review']=df.review.apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHeZDMd_VgYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "1ffeda5d-9b09-4084-f71f-0bcfda242ddf"
      },
      "source": [
        "print (\"No.of samples \\n:\",(len(df)))\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of samples \n",
            ": 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "      <td>watching time chasers it obvious that it was m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "      <td>i saw this film about years ago and remember i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "      <td>minor spoilers br br in new york joan barnard ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "      <td>i went to see this film with a great deal of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "      <td>yes i agree with everyone on this site this mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                       clean_review\n",
              "0   \"9999_0\"  ...  watching time chasers it obvious that it was m...\n",
              "1  \"45057_0\"  ...  i saw this film about years ago and remember i...\n",
              "2  \"15561_0\"  ...  minor spoilers br br in new york joan barnard ...\n",
              "3   \"7161_0\"  ...  i went to see this film with a great deal of e...\n",
              "4  \"43971_0\"  ...  yes i agree with everyone on this site this mo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNJTEEfEVulW",
        "colab_type": "text"
      },
      "source": [
        "If we look at the data now, we'll not notice any punctuations in the **clean_review** column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4rX0WQCVyeG",
        "colab_type": "text"
      },
      "source": [
        "#  Word2Vec with Gensim(The Word2Vec toolkit)\n",
        "\n",
        "Gensim is an open source Python library for natural language processing, with a focus on topic modeling.Gensim was developed and is maintained by the Czech natural language processing researcher **Radim Řehůřek** and his company RaRe Technologies.\n",
        "\n",
        "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. Most notably for this tutorial, it supports an implementation of the** Word2Vec word embedding** for learning new word vectors from text.\n",
        "\n",
        "It also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, we dig a little \"deeper\" into sentiment analysis. Google's Word2Vec is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning and **semantic relationships** among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYZt4SD1WANv",
        "colab_type": "text"
      },
      "source": [
        "**Please install & import the gensim everytime you work on Google colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSzjbZgyVn0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim --quiet     "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBHMk9ubWDkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-llKWangWJrj",
        "colab_type": "text"
      },
      "source": [
        "**Since we are going to work with words, so we are required to split the each review so that we can have word tokens.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0To07JgeWGSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Document=[]\n",
        "for doc in df['clean_review']:\n",
        "  Document.append(doc.split(' '))  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONYgBaZWOKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "922ea028-cd60-495f-fde7-44f7f0bed831"
      },
      "source": [
        "len(Document)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jYvy2DhWXYu",
        "colab_type": "text"
      },
      "source": [
        "**Let us explore split reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7q0fBDWUOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57a7b60a-a03f-43c0-b2e3-3eaf0d76ea07"
      },
      "source": [
        "Document[10][6:13]     "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie', 'i', 'am', 'not', 'sure', 'whether', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQYAZZRCWa4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f300e37c-6a19-4fb4-8cb2-b11d05fad991"
      },
      "source": [
        "print(len(Document[10]))                                                          # Lenth of the 10th document ,  It has 524 words in it\n",
        "print(Document[10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "524\n",
            "['after', 'reading', 'the', 'comments', 'for', 'this', 'movie', 'i', 'am', 'not', 'sure', 'whether', 'i', 'should', 'be', 'angry', 'sad', 'or', 'sickened', 'seeing', 'comments', 'typical', 'of', 'people', 'who', 'a', 'know', 'absolutely', 'nothing', 'about', 'the', 'military', 'or', 'b', 'who', 'base', 'everything', 'they', 'think', 'they', 'know', 'on', 'movies', 'like', 'this', 'or', 'on', 'cnn', 'reports', 'about', 'abu', 'gharib', 'makes', 'me', 'wonder', 'about', 'the', 'state', 'of', 'intellectual', 'stimulation', 'in', 'the', 'world', 'br', 'br', 'at', 'the', 'time', 'i', 'type', 'this', 'the', 'number', 'of', 'people', 'in', 'the', 'us', 'military', 'million', 'on', 'active', 'duty', 'with', 'another', 'almost', 'in', 'the', 'guard', 'and', 'reserves', 'for', 'a', 'total', 'of', 'roughly', 'million', 'br', 'br', 'the', 'number', 'of', 'people', 'indicted', 'for', 'abuses', 'at', 'at', 'abu', 'gharib', 'currently', 'less', 'than', 'br', 'br', 'that', 'makes', 'the', 'total', 'of', 'people', 'indicted', 'of', 'the', 'total', 'military', 'even', 'if', 'you', 'indict', 'every', 'single', 'military', 'member', 'that', 'ever', 'stepped', 'in', 'to', 'abu', 'gharib', 'you', 'would', 'not', 'come', 'close', 'to', 'making', 'that', 'a', 'whole', 'number', 'br', 'br', 'the', 'flaws', 'in', 'this', 'movie', 'would', 'take', 'years', 'to', 'cover', 'i', 'understand', 'that', 'it', 's', 'supposed', 'to', 'be', 'sarcastic', 'but', 'in', 'reality', 'the', 'writer', 'and', 'director', 'are', 'trying', 'to', 'make', 'commentary', 'about', 'the', 'state', 'of', 'the', 'military', 'without', 'an', 'enemy', 'to', 'fight', 'in', 'reality', 'the', 'us', 'military', 'has', 'been', 'at', 'its', 'busiest', 'when', 'there', 'are', 'not', 'conflicts', 'going', 'on', 'the', 'military', 'is', 'the', 'first', 'called', 'for', 'disaster', 'relief', 'and', 'humanitarian', 'aid', 'missions', 'when', 'the', 'tsunami', 'hit', 'indonesia', 'devestating', 'the', 'region', 'the', 'us', 'military', 'was', 'the', 'first', 'on', 'the', 'scene', 'when', 'the', 'chaos', 'of', 'the', 'situation', 'overwhelmed', 'the', 'local', 'governments', 'it', 'was', 'military', 'leadership', 'who', 'looked', 'at', 'their', 'people', 'the', 'same', 'people', 'this', 'movie', 'mocks', 'and', 'said', 'make', 'it', 'happen', 'within', 'hours', 'food', 'aid', 'was', 'reaching', 'isolated', 'villages', 'within', 'days', 'airfields', 'were', 'built', 'cargo', 'aircraft', 'started', 'landing', 'and', 'a', 'food', 'distribution', 'system', 'was', 'up', 'and', 'running', 'hours', 'and', 'days', 'not', 'weeks', 'and', 'months', 'yes', 'there', 'are', 'unscrupulous', 'people', 'in', 'the', 'us', 'military', 'but', 'then', 'there', 'are', 'in', 'every', 'walk', 'of', 'life', 'every', 'occupation', 'but', 'to', 'see', 'people', 'on', 'this', 'website', 'decide', 'that', 'million', 'men', 'and', 'women', 'are', 'all', 'criminal', 'with', 'nothing', 'on', 'their', 'minds', 'but', 'thoughts', 'of', 'destruction', 'or', 'mayhem', 'is', 'an', 'absolute', 'disservice', 'to', 'the', 'things', 'that', 'they', 'do', 'every', 'day', 'one', 'person', 'on', 'this', 'website', 'even', 'went', 'so', 'far', 'as', 'to', 'say', 'that', 'military', 'members', 'are', 'in', 'it', 'for', 'personal', 'gain', 'wow', 'entry', 'level', 'personnel', 'make', 'just', 'under', 'an', 'hour', 'assuming', 'a', 'hour', 'work', 'week', 'of', 'course', 'many', 'work', 'much', 'more', 'than', 'hours', 'a', 'week', 'and', 'those', 'in', 'harm', 's', 'way', 'typically', 'put', 'in', 'hour', 'days', 'for', 'months', 'on', 'end', 'that', 'makes', 'the', 'pay', 'well', 'under', 'minimum', 'wage', 'so', 'much', 'for', 'personal', 'gain', 'i', 'beg', 'you', 'please', 'make', 'yourself', 'familiar', 'with', 'the', 'world', 'around', 'you', 'go', 'to', 'a', 'nearby', 'base', 'get', 'a', 'visitor', 'pass', 'and', 'meet', 'some', 'of', 'the', 'men', 'and', 'women', 'you', 'are', 'so', 'quick', 'to', 'disparage', 'you', 'would', 'be', 'surprised', 'the', 'military', 'no', 'longer', 'accepts', 'people', 'in', 'lieu', 'of', 'prison', 'time', 'they', 'require', 'a', 'minimum', 'of', 'a', 'ged', 'and', 'prefer', 'a', 'high', 'school', 'diploma', 'the', 'middle', 'ranks', 'are', 'expected', 'to', 'get', 'a', 'minimum', 'of', 'undergraduate', 'degrees', 'and', 'the', 'upper', 'ranks', 'are', 'encouraged', 'to', 'get', 'advanced', 'degrees']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEvVsLzHWenO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZuL6WySW1us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4dc5d51f-796b-4bce-b3a0-226d597e64e1"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "model=gensim.models.Word2Vec(Document,                                           # List of reviews\n",
        "                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n",
        "                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n",
        "                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n",
        "                          window=5)                                              # 5 neighbors on the either side of a word"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-23 09:46:57,375 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2020-09-23 09:46:57,380 : INFO : collecting all words and their counts\n",
            "2020-09-23 09:46:57,384 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-09-23 09:46:57,867 : INFO : PROGRESS: at sentence #10000, processed 2399440 words, keeping 51654 word types\n",
            "2020-09-23 09:46:58,410 : INFO : PROGRESS: at sentence #20000, processed 4835846 words, keeping 69077 word types\n",
            "2020-09-23 09:46:58,893 : INFO : PROGRESS: at sentence #30000, processed 7267977 words, keeping 81515 word types\n",
            "2020-09-23 09:46:59,379 : INFO : PROGRESS: at sentence #40000, processed 9669772 words, keeping 91685 word types\n",
            "2020-09-23 09:46:59,850 : INFO : collected 100479 word types from a corpus of 12084660 raw words and 50000 sentences\n",
            "2020-09-23 09:46:59,852 : INFO : Loading a fresh vocabulary\n",
            "2020-09-23 09:47:00,236 : INFO : effective_min_count=10 retains 28322 unique words (28% of original 100479, drops 72157)\n",
            "2020-09-23 09:47:00,237 : INFO : effective_min_count=10 leaves 11910457 word corpus (98% of original 12084660, drops 174203)\n",
            "2020-09-23 09:47:00,336 : INFO : deleting the raw counts dictionary of 100479 items\n",
            "2020-09-23 09:47:00,341 : INFO : sample=0.001 downsamples 49 most-common words\n",
            "2020-09-23 09:47:00,342 : INFO : downsampling leaves estimated 8817283 word corpus (74.0% of prior 11910457)\n",
            "2020-09-23 09:47:00,421 : INFO : estimated required memory for 28322 words and 50 dimensions: 25489800 bytes\n",
            "2020-09-23 09:47:00,422 : INFO : resetting layer weights\n",
            "2020-09-23 09:47:06,846 : INFO : training model with 4 workers on 28322 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-09-23 09:47:07,870 : INFO : EPOCH 1 - PROGRESS: at 6.08% examples, 528563 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:08,888 : INFO : EPOCH 1 - PROGRESS: at 12.41% examples, 533131 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:09,888 : INFO : EPOCH 1 - PROGRESS: at 18.75% examples, 541181 words/s, in_qsize 8, out_qsize 0\n",
            "2020-09-23 09:47:10,893 : INFO : EPOCH 1 - PROGRESS: at 24.52% examples, 532584 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:11,908 : INFO : EPOCH 1 - PROGRESS: at 30.64% examples, 531877 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:12,920 : INFO : EPOCH 1 - PROGRESS: at 36.83% examples, 533989 words/s, in_qsize 8, out_qsize 0\n",
            "2020-09-23 09:47:13,925 : INFO : EPOCH 1 - PROGRESS: at 42.89% examples, 535093 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:14,935 : INFO : EPOCH 1 - PROGRESS: at 48.68% examples, 531964 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:47:15,960 : INFO : EPOCH 1 - PROGRESS: at 54.96% examples, 532878 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:16,970 : INFO : EPOCH 1 - PROGRESS: at 61.26% examples, 535028 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:17,973 : INFO : EPOCH 1 - PROGRESS: at 67.37% examples, 535613 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:19,000 : INFO : EPOCH 1 - PROGRESS: at 73.73% examples, 535788 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:20,013 : INFO : EPOCH 1 - PROGRESS: at 79.99% examples, 535921 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:21,016 : INFO : EPOCH 1 - PROGRESS: at 86.12% examples, 535951 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:22,021 : INFO : EPOCH 1 - PROGRESS: at 91.93% examples, 534440 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:23,047 : INFO : EPOCH 1 - PROGRESS: at 98.24% examples, 534974 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:23,284 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-23 09:47:23,290 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-23 09:47:23,297 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-23 09:47:23,303 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-23 09:47:23,304 : INFO : EPOCH - 1 : training on 12084660 raw words (8816141 effective words) took 16.5s, 535934 effective words/s\n",
            "2020-09-23 09:47:24,332 : INFO : EPOCH 2 - PROGRESS: at 6.17% examples, 532622 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:25,338 : INFO : EPOCH 2 - PROGRESS: at 12.51% examples, 538206 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:47:26,349 : INFO : EPOCH 2 - PROGRESS: at 18.84% examples, 542730 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:27,354 : INFO : EPOCH 2 - PROGRESS: at 25.01% examples, 542385 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:28,358 : INFO : EPOCH 2 - PROGRESS: at 31.03% examples, 539671 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:29,370 : INFO : EPOCH 2 - PROGRESS: at 37.15% examples, 539235 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:30,373 : INFO : EPOCH 2 - PROGRESS: at 43.30% examples, 540598 words/s, in_qsize 8, out_qsize 0\n",
            "2020-09-23 09:47:31,375 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 538343 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:47:32,392 : INFO : EPOCH 2 - PROGRESS: at 55.35% examples, 538238 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:33,400 : INFO : EPOCH 2 - PROGRESS: at 61.26% examples, 536491 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:47:34,419 : INFO : EPOCH 2 - PROGRESS: at 67.29% examples, 535572 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:35,436 : INFO : EPOCH 2 - PROGRESS: at 73.40% examples, 534454 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:36,439 : INFO : EPOCH 2 - PROGRESS: at 79.74% examples, 535668 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:37,460 : INFO : EPOCH 2 - PROGRESS: at 86.03% examples, 536006 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:47:38,469 : INFO : EPOCH 2 - PROGRESS: at 92.27% examples, 536747 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:47:39,485 : INFO : EPOCH 2 - PROGRESS: at 98.49% examples, 536998 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:47:39,687 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-23 09:47:39,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-23 09:47:39,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-23 09:47:39,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-23 09:47:39,709 : INFO : EPOCH - 2 : training on 12084660 raw words (8816951 effective words) took 16.4s, 537678 effective words/s\n",
            "2020-09-23 09:47:40,732 : INFO : EPOCH 3 - PROGRESS: at 6.18% examples, 535681 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:47:41,733 : INFO : EPOCH 3 - PROGRESS: at 12.32% examples, 534186 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:42,783 : INFO : EPOCH 3 - PROGRESS: at 18.68% examples, 533235 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:47:43,787 : INFO : EPOCH 3 - PROGRESS: at 24.83% examples, 535448 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:44,805 : INFO : EPOCH 3 - PROGRESS: at 31.12% examples, 536815 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:45,809 : INFO : EPOCH 3 - PROGRESS: at 37.23% examples, 537538 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:46,825 : INFO : EPOCH 3 - PROGRESS: at 43.30% examples, 537182 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:47,839 : INFO : EPOCH 3 - PROGRESS: at 49.25% examples, 535515 words/s, in_qsize 8, out_qsize 0\n",
            "2020-09-23 09:47:48,845 : INFO : EPOCH 3 - PROGRESS: at 55.44% examples, 536343 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:49,854 : INFO : EPOCH 3 - PROGRESS: at 61.58% examples, 536881 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:50,855 : INFO : EPOCH 3 - PROGRESS: at 67.55% examples, 536214 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:51,862 : INFO : EPOCH 3 - PROGRESS: at 73.81% examples, 536659 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:52,862 : INFO : EPOCH 3 - PROGRESS: at 79.97% examples, 536665 words/s, in_qsize 6, out_qsize 0\n",
            "2020-09-23 09:47:53,882 : INFO : EPOCH 3 - PROGRESS: at 86.11% examples, 535979 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:47:54,890 : INFO : EPOCH 3 - PROGRESS: at 91.95% examples, 534357 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:55,895 : INFO : EPOCH 3 - PROGRESS: at 98.00% examples, 534256 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:56,172 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-23 09:47:56,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-23 09:47:56,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-23 09:47:56,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-23 09:47:56,197 : INFO : EPOCH - 3 : training on 12084660 raw words (8818214 effective words) took 16.5s, 535039 effective words/s\n",
            "2020-09-23 09:47:57,211 : INFO : EPOCH 4 - PROGRESS: at 6.00% examples, 526332 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:58,228 : INFO : EPOCH 4 - PROGRESS: at 12.24% examples, 528887 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:47:59,233 : INFO : EPOCH 4 - PROGRESS: at 18.44% examples, 532927 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:00,255 : INFO : EPOCH 4 - PROGRESS: at 24.68% examples, 534489 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:01,264 : INFO : EPOCH 4 - PROGRESS: at 30.79% examples, 534301 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:02,272 : INFO : EPOCH 4 - PROGRESS: at 36.92% examples, 535081 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:03,300 : INFO : EPOCH 4 - PROGRESS: at 43.04% examples, 535224 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:04,342 : INFO : EPOCH 4 - PROGRESS: at 49.26% examples, 534550 words/s, in_qsize 7, out_qsize 1\n",
            "2020-09-23 09:48:05,372 : INFO : EPOCH 4 - PROGRESS: at 55.20% examples, 531762 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:06,401 : INFO : EPOCH 4 - PROGRESS: at 61.32% examples, 531668 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:07,415 : INFO : EPOCH 4 - PROGRESS: at 67.45% examples, 532109 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:08,432 : INFO : EPOCH 4 - PROGRESS: at 73.81% examples, 533186 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:09,430 : INFO : EPOCH 4 - PROGRESS: at 79.99% examples, 533391 words/s, in_qsize 5, out_qsize 2\n",
            "2020-09-23 09:48:10,459 : INFO : EPOCH 4 - PROGRESS: at 86.44% examples, 534612 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:11,474 : INFO : EPOCH 4 - PROGRESS: at 92.59% examples, 534772 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:12,489 : INFO : EPOCH 4 - PROGRESS: at 98.84% examples, 535210 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:48:12,638 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-23 09:48:12,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-23 09:48:12,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-23 09:48:12,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-23 09:48:12,662 : INFO : EPOCH - 4 : training on 12084660 raw words (8818294 effective words) took 16.5s, 535813 effective words/s\n",
            "2020-09-23 09:48:13,696 : INFO : EPOCH 5 - PROGRESS: at 5.91% examples, 510139 words/s, in_qsize 5, out_qsize 2\n",
            "2020-09-23 09:48:14,730 : INFO : EPOCH 5 - PROGRESS: at 12.41% examples, 526874 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:15,743 : INFO : EPOCH 5 - PROGRESS: at 18.75% examples, 534637 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:16,746 : INFO : EPOCH 5 - PROGRESS: at 24.53% examples, 527940 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:48:17,761 : INFO : EPOCH 5 - PROGRESS: at 30.80% examples, 531092 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:48:18,790 : INFO : EPOCH 5 - PROGRESS: at 37.15% examples, 533960 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:19,793 : INFO : EPOCH 5 - PROGRESS: at 43.23% examples, 535140 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:20,794 : INFO : EPOCH 5 - PROGRESS: at 49.25% examples, 535452 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-23 09:48:21,802 : INFO : EPOCH 5 - PROGRESS: at 55.52% examples, 536919 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:22,834 : INFO : EPOCH 5 - PROGRESS: at 61.73% examples, 536777 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-23 09:48:23,836 : INFO : EPOCH 5 - PROGRESS: at 67.98% examples, 537968 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:24,841 : INFO : EPOCH 5 - PROGRESS: at 74.12% examples, 537765 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:25,846 : INFO : EPOCH 5 - PROGRESS: at 80.55% examples, 539118 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:26,873 : INFO : EPOCH 5 - PROGRESS: at 86.76% examples, 538549 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:27,879 : INFO : EPOCH 5 - PROGRESS: at 92.69% examples, 537328 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:28,884 : INFO : EPOCH 5 - PROGRESS: at 98.75% examples, 537019 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-23 09:48:29,046 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-23 09:48:29,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-23 09:48:29,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-23 09:48:29,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-23 09:48:29,063 : INFO : EPOCH - 5 : training on 12084660 raw words (8817295 effective words) took 16.4s, 537870 effective words/s\n",
            "2020-09-23 09:48:29,065 : INFO : training on a 60423300 raw words (44086895 effective words) took 82.2s, 536224 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgLNqmhyXCwM",
        "colab_type": "text"
      },
      "source": [
        "**Please note that after applying Word2Vec function on the clean_review giving all the arguments corretly we have got 28322 words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIfV1hV2W98g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15dc31ff-957f-4414-8387-3878bf0f3c2d"
      },
      "source": [
        "print(len(model.wv.vocab)) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUWynD2OXhsO",
        "colab_type": "text"
      },
      "source": [
        "**Let's check the dimension of a vector i.e. the number of words that represent a word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKot3NKSXe4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc2c06e3-6e6d-45e1-90df-a649ce7254c5"
      },
      "source": [
        "print(model.wv.vector_size)  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6vycKBQXkko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5de87d2-8e8c-461a-c2e9-d0f1832fa184"
      },
      "source": [
        "model.wv.vectors.shape "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28322, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lerDgijYXsl2",
        "colab_type": "text"
      },
      "source": [
        "### Let's explore some interesting results of word2vec experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS5arA09Xo_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "0beab6e4-7f0a-451d-fb93-e0b8b00a6bdd"
      },
      "source": [
        "model.wv.most_similar(\"beautiful\")   # 10 similar words beautiful,the maximum similarity is 1,minimum is 0.When they are completely similar the \n",
        "                                                                                  # Value will be 1 , when completely dissimilar,the value will be 0."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-23 09:50:22,141 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8498616218566895),\n",
              " ('lovely', 0.813451886177063),\n",
              " ('stunning', 0.8121933937072754),\n",
              " ('wonderful', 0.7573546171188354),\n",
              " ('haunting', 0.7496060132980347),\n",
              " ('breathtaking', 0.7036622762680054),\n",
              " ('touching', 0.6950976848602295),\n",
              " ('fabulous', 0.6866289973258972),\n",
              " ('delightful', 0.6850804090499878),\n",
              " ('magnificent', 0.6806464791297913)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hHb8ik7XwLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "0d46e603-691b-4727-cf83-7f1b863ceffd"
      },
      "source": [
        "model.wv.most_similar(\"princess\")                                                  # 10 similar words returned with numbers"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.848441481590271),\n",
              " ('widow', 0.8242537379264832),\n",
              " ('maid', 0.8132736086845398),\n",
              " ('nurse', 0.8021011352539062),\n",
              " ('servant', 0.7945051789283752),\n",
              " ('belle', 0.7807425260543823),\n",
              " ('mistress', 0.7736099362373352),\n",
              " ('katie', 0.7735347747802734),\n",
              " ('maria', 0.7725345492362976),\n",
              " ('connie', 0.7707166075706482)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p_Yk3T4X8v4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "24263cde-a42a-40bf-a361-87116e77c0af"
      },
      "source": [
        "model.wv.doesnt_match(\"she talked to me in the evening publicly\".split())         # publicly does not match in the sentence given"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'publicly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JNZM25cYJso",
        "colab_type": "text"
      },
      "source": [
        "Below the word **right** is represented by a dense 50 dimensional vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDkCk5p9YByw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6a57d33d-ce72-4922-a7dd-64d367a17512"
      },
      "source": [
        "model.wv[\"right\"]                                                                  # right word is represented by 50 numbers in other words the word \"right\" is vector of 50 numbers\n",
        "                                                                                   # 50 numbers are summarized weights because these numbers are obtained in the hidden layer of predefined 50 neurons"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.58482987,  0.37276646,  4.3139997 ,  1.1162901 , -3.2966876 ,\n",
              "       -1.0363513 ,  1.6049155 , -1.1897538 , -0.51993334,  0.6361889 ,\n",
              "       -0.7960794 ,  1.365439  ,  2.5716636 , -1.101285  ,  0.96635634,\n",
              "       -0.06711897,  1.3096476 ,  0.9245065 , -1.2487943 , -1.5867445 ,\n",
              "        0.96848917, -0.17020777,  1.1714509 ,  0.97659427, -0.34997207,\n",
              "        0.5747086 ,  0.16904445,  0.06621201, -0.78070676, -0.4459674 ,\n",
              "       -1.8318795 , -0.63698816, -0.52165806, -1.490284  ,  1.4324033 ,\n",
              "        1.0249132 ,  0.5278931 , -0.56304586, -2.454342  ,  2.0688403 ,\n",
              "       -1.7150204 ,  0.703759  ,  1.4021444 ,  0.8832156 ,  1.7617977 ,\n",
              "       -1.468824  ,  1.0558372 , -0.87220806, -0.73403037, -0.68236196],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLxgeAqYOqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4728a495-b9e0-4da0-819f-f0cf65f4c432"
      },
      "source": [
        "model.wv['great']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.9054477 , -0.7499229 ,  4.01928   ,  0.7254148 , -0.98956865,\n",
              "        1.188865  ,  0.27326736, -2.2435625 , -1.5555571 ,  1.442838  ,\n",
              "        0.6180451 ,  1.4773593 ,  2.3255615 , -0.3421548 ,  2.3044271 ,\n",
              "        0.8625231 ,  2.224525  ,  1.2045219 ,  0.80200946, -1.3115244 ,\n",
              "        0.98753154, -0.0264725 , -0.586872  ,  0.17582227, -0.01529712,\n",
              "       -2.0365381 ,  0.0304117 , -2.8428738 , -3.2359104 , -1.7251419 ,\n",
              "        0.71908975, -0.00965737,  1.4087237 , -0.56708026, -0.78146267,\n",
              "        0.78369546, -3.476549  ,  2.323809  , -0.38289136, -0.39009288,\n",
              "        0.66047275,  0.12427082,  4.268108  , -1.9506902 ,  4.217624  ,\n",
              "       -2.2324438 , -2.4205093 , -2.106239  ,  2.9360704 , -1.6193236 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50njYQw0YYCk",
        "colab_type": "text"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV0yq2H5YRX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e863ec33-f83d-4a86-9b9a-d195f8dcbd85"
      },
      "source": [
        "model.save(\"word2vec movie-50\")                                                    # We save this model for further use.\n",
        "                                                                                   # Google has such many pre-trained models"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-23 09:53:25,669 : INFO : saving Word2Vec object under word2vec movie-50, separately None\n",
            "2020-09-23 09:53:25,671 : INFO : not storing attribute vectors_norm\n",
            "2020-09-23 09:53:25,673 : INFO : not storing attribute cum_table\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-09-23 09:53:25,855 : INFO : saved word2vec movie-50\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45-X0bobYgtp",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with pre-trained Word2Vec model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEFNs6mDYjlQ",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "In this tutorial we'll do Sentiment analysis based on the concept of Word2Vec using our **pre-trained model** with unlabelled data where we've applied **Word2Vec** technique i.e representing a word with a dense vector of **50 numbers**. The unlabelled data has **50000 IMDB movie reviews** & we extracted  some **28000+** unique words after doing some data preprocessing & applying Word2Vec technique with length of 50 numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-1x59Q2YqZu",
        "colab_type": "text"
      },
      "source": [
        "Set the seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OnCIyoGYctv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsru7f-xY0hH",
        "colab_type": "text"
      },
      "source": [
        "###Load data\n",
        "Data can be downloaded from Kaggle -> https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ6NjLz3YUWB",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6dab8441-ed88-44dc-9afd-a5fdffaeb2bc"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb731b13-bd3f-49dd-ba7c-c98cb3eaf335\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb731b13-bd3f-49dd-ba7c-c98cb3eaf335\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving labeledTrainData_lyst3830.tsv to labeledTrainData_lyst3830.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkaPYYbbY7w6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10fc080c-6255-4c3f-d3f4-ff3f069f2cb0"
      },
      "source": [
        "df1 = pd.read_csv('labeledTrainData_lyst3830.tsv',  #filepath\n",
        "                 header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "print(df1.shape)  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm3kVr9Gbjp6",
        "colab_type": "text"
      },
      "source": [
        "## About the data\n",
        "\n",
        "The labelled data set contains 25000 reviews with label(**Sentiment**). The output column  Sentiment consists of 2 categories[0 & 1]. \n",
        "\n",
        "**0 -- Indicates negative sentiment **               ,  if the rating < 5\n",
        "\n",
        "**1-- Indicates positive sentiment **                  , if the rating >= 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRfa9qCMbgDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e4956933-5ad1-4ea8-c9c8-f8dc9e141388"
      },
      "source": [
        "df1.iloc[10:15,:]                                                                  # Have 10th & 11th review of the dataset alongwith review id, sentiment."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"11744_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\"7369_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I had a feeling that after \\\"Submerged\\\", thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\"12081_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"note to George Litman, and others: the Myster...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli...\n",
              "12  \"11744_9\"          1  \"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...\n",
              "13   \"7369_1\"          0  \"I had a feeling that after \\\"Submerged\\\", thi...\n",
              "14  \"12081_1\"          0  \"note to George Litman, and others: the Myster..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-5MoXJ9byHh",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPWOh9Oyb1BH",
        "colab_type": "text"
      },
      "source": [
        "**1.Split Data into Training and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRF5D7zTbqFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df1['review'],\n",
        "    df1['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELf6c7tYcKfK",
        "colab_type": "text"
      },
      "source": [
        "**2.Build Tokenizer to get Number sequences for Each review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGvS1qNLb8KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vocab size\n",
        "top_words = 10000\n",
        "\n",
        "t = Tokenizer(num_words=top_words)\n",
        "t.fit_on_texts(X_train.tolist())\n",
        "\n",
        "#Get the word index for each of the word in the review\n",
        "X_train = t.texts_to_sequences(X_train.tolist())\n",
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ZtMoMdcvpF",
        "colab_type": "text"
      },
      "source": [
        "**3.Pad sequences to make each review size equal Get the word index for each of the word in the review**\n",
        "\n",
        "We  want to bring all the reviewa into same length because we want to build matrix with this dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snFZut5Rcn9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "\n",
        "#Each review size\n",
        "max_review_length = 300\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post') "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBYfQi4dCAs",
        "colab_type": "text"
      },
      "source": [
        "## Build Embedding Matrix from Pre-Trained Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX0DmPwTcy9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "61b08947-e527-4676-f51f-923e8a7f90c0"
      },
      "source": [
        "#Install gensim\n",
        "!pip install gensim --quiet\n",
        "\n",
        "#Load pre-trained model\n",
        "import gensim\n",
        "word2vec = gensim.models.Word2Vec.load('word2vec movie-50')\n",
        "\n",
        "#Embedding Length\n",
        "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
        "\n",
        "print('Loaded word2vec model..')\n",
        "print('Model shape: ', word2vec.wv.vectors.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-23 10:14:16,372 : INFO : loading Word2Vec object from word2vec movie-50\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-09-23 10:14:16,519 : INFO : loading wv recursively from word2vec movie-50.wv.* with mmap=None\n",
            "2020-09-23 10:14:16,520 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-09-23 10:14:16,521 : INFO : loading vocabulary recursively from word2vec movie-50.vocabulary.* with mmap=None\n",
            "2020-09-23 10:14:16,522 : INFO : loading trainables recursively from word2vec movie-50.trainables.* with mmap=None\n",
            "2020-09-23 10:14:16,524 : INFO : setting ignored attribute cum_table to None\n",
            "2020-09-23 10:14:16,526 : INFO : loaded word2vec movie-50\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded word2vec model..\n",
            "Model shape:  (28322, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYavWGSOdNp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "574ac28c-2ba4-4755-91ce-0a7b7bac620e"
      },
      "source": [
        "word2vec.wv.vector_size"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXzgo_tEdWN8",
        "colab_type": "text"
      },
      "source": [
        "**Build matrix for current data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOR5iYfMdTLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize embedding matrix to all zeros\n",
        "embedding_matrix = np.zeros((top_words + 1, # Vocablury size + 1,, we add 1 to vocab size for padding\n",
        "                             embedding_vector_length))\n",
        "\n",
        "#Steps for populating embedding matrix\n",
        "\n",
        "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
        "# word2vec model.\n",
        "#2. If found, update embedding matrix with embeddings for the word \n",
        "# from word2vec model\n",
        "\n",
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > top_words:\n",
        "        break\n",
        "    if word in word2vec.wv.vocab:\n",
        "        embedding_vector = word2vec.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt4leK00djpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a17a72a0-fdef-4d03-dad9-31669a017c3a"
      },
      "source": [
        "#Check embeddings for word 'great'\n",
        "embedding_matrix[t.word_index['great']]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.90544772, -0.74992287,  4.01927996,  0.72541481, -0.98956865,\n",
              "        1.18886495,  0.27326736, -2.24356246, -1.55555713,  1.44283795,\n",
              "        0.61804509,  1.47735929,  2.32556152, -0.3421548 ,  2.30442715,\n",
              "        0.86252308,  2.22452497,  1.20452189,  0.80200946, -1.31152439,\n",
              "        0.98753154, -0.0264725 , -0.58687198,  0.17582227, -0.01529712,\n",
              "       -2.03653812,  0.0304117 , -2.84287381, -3.23591042, -1.72514188,\n",
              "        0.71908975, -0.00965737,  1.40872371, -0.56708026, -0.78146267,\n",
              "        0.78369546, -3.47654891,  2.32380891, -0.38289136, -0.39009288,\n",
              "        0.66047275,  0.12427082,  4.26810789, -1.95069015,  4.21762419,\n",
              "       -2.23244381, -2.42050934, -2.10623908,  2.93607044, -1.61932361])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6J1CSiTdqQs",
        "colab_type": "text"
      },
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-teD4Zudm0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten\n",
        "\n",
        "#Build a sequential model\n",
        "model1 = Sequential()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SPQBRPrdw2A",
        "colab_type": "text"
      },
      "source": [
        "**Add Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_F8f4x-durw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.add(Embedding(top_words + 1,\n",
        "                    embedding_vector_length,\n",
        "                    input_length=max_review_length,\n",
        "                    weights=[embedding_matrix],                                    # Pre-trained embedding\n",
        "                    trainable=False)                                               # We do not want to change embedding\n",
        "         )"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb4E4t-9d3gp",
        "colab_type": "text"
      },
      "source": [
        "Output from Embedding is 3 dimension \n",
        "- batch_size x max_review_length x embedding_vector_length. \n",
        "\n",
        "We need to flatten the output for Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqtrUU1ed1Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Flatten embedding layer output and flatten layers\n",
        "model1.add(Flatten())                                                             # Flatten enables us to bring down the dimension of the prepared data\n",
        "model1.add(Dense(200,activation='relu'))                                          # Dense layer is for fully connected layer\n",
        "model1.add(Dense(100,activation='relu'))\n",
        "model1.add(Dropout(0.5))                                                          # Dropout is required to avoid overfiting & make the model generalize\n",
        "model1.add(Dense(60,activation='relu'))\n",
        "model1.add(Dropout(0.4))\n",
        "model1.add(Dense(30,activation='relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(1,activation='sigmoid'))                                         # We've used sigmoid because output variable is binary\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmw7DCPdd8Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.utils import to_categorical\n",
        "#Y_train=to_categorical(y_train,2)\n",
        "#Y_test=to_categorical(y_test,2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKX9MUqJeCq7",
        "colab_type": "text"
      },
      "source": [
        "## Execute the graph\n",
        "\n",
        "Here we'll  use split data to find train & validation accuracy with 10 iterations on 20000 train data & 5000 validation data with batch size of 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZjES36DeAAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "223fe84e-227f-4dca-b8eb-74eaa97a15e7"
      },
      "source": [
        "model1.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=200,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.7320 - accuracy: 0.5313 - val_loss: 0.6431 - val_accuracy: 0.6454\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5938 - accuracy: 0.6896 - val_loss: 0.5322 - val_accuracy: 0.7400\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4553 - accuracy: 0.7998 - val_loss: 0.5038 - val_accuracy: 0.7602\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3524 - accuracy: 0.8548 - val_loss: 0.5250 - val_accuracy: 0.7620\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2466 - accuracy: 0.9024 - val_loss: 0.6024 - val_accuracy: 0.7542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa82e0c84e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv41S3RqeGtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b442db54-6633-4aa3-d422-6807210dbae8"
      },
      "source": [
        "model1.predict(X_test[10:12])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40556923],\n",
              "       [0.02359332]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNk1xXkieLg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "761842b1-0735-4fa0-f864-f1e514f24f64"
      },
      "source": [
        "df1.iloc[10:12,:]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wfSlCx_ePj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}